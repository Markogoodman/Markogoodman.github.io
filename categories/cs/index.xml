<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" 
  xmlns:content="http://purl.org/rss/1.0/modules/content/" 
  xmlns:dc="http://purl.org/dc/elements/1.1/" 
  xmlns:atom="http://www.w3.org/2005/Atom" 
  xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" 
  xmlns:media="http://search.yahoo.com/mrss/">
  <channel>
    <title>CS on Marko</title>
    <link>https://markogoodman.github.io/categories/cs/</link>
    <description>Recent content in CS on Marko</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>marko958m@gmail.com (Marko Peng)</managingEditor>
    <webMaster>marko958m@gmail.com (Marko Peng)</webMaster>
    <copyright>Â©{2020}, All Rights Reserved</copyright>
    <lastBuildDate>Fri, 19 Dec 2025 16:37:39 -0500</lastBuildDate>
    
        <atom:link href="https://markogoodman.github.io/categories/cs/index.xml" rel="self" type="application/rss+xml" />
    
    
    

      
      <item>
        <title>Attention and Transformer</title>
        <link>https://markogoodman.github.io/posts/attention-and-tranformer/</link>
        <pubDate>Fri, 19 Dec 2025 16:37:39 -0500</pubDate>
        <author>marko958m@gmail.com (Marko Peng)</author>
        <atom:modified>Fri, 19 Dec 2025 16:37:39 -0500</atom:modified>
        <guid>https://markogoodman.github.io/posts/attention-and-tranformer/</guid>
        <description>Writting down some notes when tring to understand these 2 things.
Some prerequisites Optional:
Neural Networks Visualized Video
A blog post about LSTM
These 2 are the earlier version of AI. It describes what neural network is and how LSTM improves it.
Not directly related to Attention and Transformer.
Required:
Word embedding. But no need to go deep. Just need to know that a matrix is used to represent a word&amp;rsquo;s meaning in a vector space.</description>
        
        <dc:creator>Marko Peng</dc:creator>
        
        
        
        
        
          
            
              <category>CS</category>
            
          
        
        
          
            
          
        
      </item>
      
      <item>
        <title>Attention and Transformer</title>
        <link>https://markogoodman.github.io/posts/attention-and-transformer/</link>
        <pubDate>Fri, 19 Dec 2025 16:37:39 -0500</pubDate>
        <author>marko958m@gmail.com (Marko Peng)</author>
        <atom:modified>Fri, 19 Dec 2025 16:37:39 -0500</atom:modified>
        <guid>https://markogoodman.github.io/posts/attention-and-transformer/</guid>
        <description>Writting down some notes when tring to understand these 2 things.
Some prerequisites Optional:
Neural Networks Visualized Video
A blog post about LSTM
These 2 are the earlier version of AI. It describes what neural network is and how LSTM improves it.
Not directly related to Attention and Transformer.
Required:
Word embedding. But no need to go deep. Just need to know that a matrix is used to represent a word&amp;rsquo;s meaning in a vector space.</description>
        
        <dc:creator>Marko Peng</dc:creator>
        
        
        
        
        
          
            
              <category>CS</category>
            
          
        
        
          
            
          
        
      </item>
      

    
  </channel>
</rss>