<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" 
  xmlns:content="http://purl.org/rss/1.0/modules/content/" 
  xmlns:dc="http://purl.org/dc/elements/1.1/" 
  xmlns:atom="http://www.w3.org/2005/Atom" 
  xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" 
  xmlns:media="http://search.yahoo.com/mrss/">
  <channel>
    <title>Spark on Marko</title>
    <link>https://markogoodman.github.io/tags/spark/</link>
    <description>Recent content in Spark on Marko</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>marko958m@gmail.com (Marko Peng)</managingEditor>
    <webMaster>marko958m@gmail.com (Marko Peng)</webMaster>
    <copyright>Â©{2020}, All Rights Reserved</copyright>
    <lastBuildDate>Sun, 02 Jul 2023 16:30:51 -0400</lastBuildDate>
    
        <atom:link href="https://markogoodman.github.io/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    
    
    

      
      <item>
        <title>How to solve spark large amount of small files problem</title>
        <link>https://markogoodman.github.io/posts/spark-small-file-problem/</link>
        <pubDate>Sun, 02 Jul 2023 16:30:51 -0400</pubDate>
        <author>marko958m@gmail.com (Marko Peng)</author>
        <atom:modified>Sun, 02 Jul 2023 16:30:51 -0400</atom:modified>
        <guid>https://markogoodman.github.io/posts/spark-small-file-problem/</guid>
        <description>How to solve spark large amout of small files problem It&amp;rsquo;s a technical issue I solved when working.
Problen Description In our data pipeline, an hourly spark job writes data to AWS S3.
The data and directory structure looks like this:
/job_name_start_time/event_timestamp_minute/data_1/job_name_start_time/event_timestamp_minute/data_2... At time T the job will process all the events generated between T-1hour ~ T.
For example, an event generated by job JobX at 2020-03-04 10:30AM will probably be stored in a file at /JobX_2020-03-04-11:00/2020-03-04-10:30/data_n.</description>
        
        <dc:creator>Marko Peng</dc:creator>
        
        
        
        
          
            
              <category>Spark</category>
            
          
        
        
          
            
              <category>Computer Science</category>
            
          
        
        
      </item>
      

    
  </channel>
</rss>